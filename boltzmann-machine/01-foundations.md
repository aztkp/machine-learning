# ボルツマンマシン：基礎編

**対象読者**: 理系大学院生（線形代数・確率論の基礎はあるが機械学習は初学者）

---

## 1. ボルツマンマシンとは

### 1.1 機械学習における位置づけ

機械学習モデルは大きく2つに分類される：

| 種類 | 目的 | 学習するもの | 例 |
|------|------|-------------|-----|
| **識別モデル** | 入力から出力を予測 | $P(y\|x)$ | SVM、ロジスティック回帰、CNN |
| **生成モデル** | データの分布を学習 | $P(x)$ または $P(x,y)$ | VAE、GAN、**ボルツマンマシン** |

**ボルツマンマシン（Boltzmann Machine）** は1985年にGeoffrey HintonとTerry Sejnowskiが提案した**確率的生成モデル**である。統計力学の概念をニューラルネットワークに応用したもので、名前は物理学者Ludwig Boltzmannに由来する。

### 1.2 なぜ「ボルツマン」なのか

統計力学において、熱平衡状態にある系がエネルギー $E$ の状態をとる確率は**ボルツマン分布**に従う：

$$P(状態) = \frac{1}{Z} \exp\left(-\frac{E}{k_B T}\right)$$

- $k_B$：ボルツマン定数
- $T$：温度
- $Z = \sum_{状態} \exp(-E/k_B T)$：分配関数（正規化定数）

**核心的な性質：低エネルギーの状態ほど高確率で実現する**

ボルツマンマシンはこの物理法則を機械学習に応用する：
- **訓練データに対応するパターン** → 低エネルギー（高確率）に
- **訓練データにないパターン** → 高エネルギー（低確率）に

つまり**学習とは、エネルギー地形を整形する過程**である。

### 1.3 歴史的背景

```
1982年 ホップフィールドネットワーク登場
       （決定論的なエネルギーベースモデル、局所最小値に陥りやすい）
         ↓
1985年 ボルツマンマシン提案
       （確率的な状態遷移で局所最小値から脱出可能に）
         ↓
1990年代 冬の時代（学習が遅く、バックプロパゲーションに押される）
         ↓
2002年 コントラスティブダイバージェンス（CD）アルゴリズム
       （Hintonが提案、学習が劇的に高速化）
         ↓
2006年 深層信念ネットワーク（DBN）
       （「深いネットワークは学習可能」を示し、ディープラーニング復興の契機に）
```

### 1.4 ニューラルネットワークの分類における位置

```
ニューラルネットワーク
├── フィードフォワード型（MLP, CNN）
├── リカレント型（RNN, LSTM, Transformer）
└── エネルギーベースモデル ← ここ
    ├── ホップフィールドネットワーク（決定論的）
    └── ボルツマンマシン（確率的）
        ├── 完全ボルツマンマシン
        ├── 制限ボルツマンマシン（RBM）
        └── 深層ボルツマンマシン（DBM）
```

---

## 2. 基礎理論

### 2.1 ユニット（ノード）

ボルツマンマシンは複数の**二値ユニット**で構成される。

$$s_i \in \{0, 1\} \quad \text{（または } \{-1, +1\}\text{）}$$

ユニットは2種類に分類される：

| 種類 | 記号 | 役割 |
|------|------|------|
| **可視ユニット** | $\mathbf{v}$ | 外部から観測可能。入力データを表現 |
| **隠れユニット** | $\mathbf{h}$ | 外部から観測不可。データの潜在的特徴を表現 |

**なぜ「隠れ」ユニットが必要か？**

機械学習では、データの背後にある「見えない構造」を学習することが重要である。例えば：
- 手書き数字画像：ピクセル値（可視）の背後に「どの数字か」という特徴（隠れ）
- 文書データ：単語（可視）の背後に「トピック」という特徴（隠れ）

隠れユニットがあることで、可視ユニットだけでは表現できない**非線形な関係**（例：XOR問題）を学習できる。

### 2.2 接続とパラメータ

ユニット間は**対称的な重み**で接続される：

- $w_{ij}$：ユニット $i$ と $j$ の間の重み（$w_{ij} = w_{ji}$）
- $w_{ii} = 0$：自己接続はなし
- $b_i$：ユニット $i$ のバイアス（活性化のしやすさを制御）

### 2.3 システムの状態と確率分布

全ユニットの状態をまとめたベクトル：

$$\mathbf{s} = (s_1, s_2, \ldots, s_n)$$

$n$ 個の二値ユニットがある場合、可能な状態は $2^n$ 通り。

状態 $\mathbf{s}$ が実現する確率（**ボルツマン分布**）：

$$P(\mathbf{s}) = \frac{1}{Z} \exp(-E(\mathbf{s})/T)$$

- $E(\mathbf{s})$：状態のエネルギー（次節で定義）
- $T$：温度パラメータ（通常 $T=1$ とする）
- $Z = \sum_{\mathbf{s}'} \exp(-E(\mathbf{s}')/T)$：分配関数

### 2.4 状態の更新規則

ユニット $i$ が活性化（$s_i = 1$）する確率：

$$P(s_i = 1 \mid \mathbf{s}_{-i}) = \sigma\left(\frac{1}{T}\left(\sum_j w_{ij} s_j + b_i\right)\right)$$

ここで $\sigma(x) = \frac{1}{1 + e^{-x}}$ はシグモイド関数、$\mathbf{s}_{-i}$ は $s_i$ 以外の全ユニットの状態。

**更新手順（ギブスサンプリング）**：
1. ユニットをランダムに1つ選ぶ
2. 他のユニットの状態から確率を計算
3. その確率に従って状態を更新
4. 1-3を繰り返す

この過程を十分繰り返すと、システムはボルツマン分布（**平衡状態**）に収束する。これは**マルコフ連鎖モンテカルロ法（MCMC）** の一種である。

### 2.5 温度の役割

| 温度 $T$ | 挙動 |
|----------|------|
| $T \to 0$ | 最低エネルギー状態のみ選ばれる（決定論的） |
| $T = 1$ | 標準的な確率的動作 |
| $T \to \infty$ | 全ての状態が等確率（完全にランダム） |

**シミュレーテッドアニーリング**：高温から始めて徐々に冷却することで、局所最小値を脱出しつつ最終的に良い解（低エネルギー状態）を見つける手法。

---

## 3. エネルギー関数

### 3.1 エネルギーベースモデルの考え方

ボルツマンマシンは**エネルギーベースモデル（Energy-Based Model, EBM）** の一種である。

核心的なアイデア：
- 「良いパターン」 = 低エネルギー状態
- 「悪いパターン」 = 高エネルギー状態

学習とは、訓練データに対応する状態のエネルギーを下げ、それ以外のエネルギーを上げることである。

### 3.2 エネルギー関数の定義

状態 $\mathbf{s}$ のエネルギー：

$$E(\mathbf{s}) = -\sum_{i<j} w_{ij} s_i s_j - \sum_i b_i s_i$$

行列表記では：

$$E(\mathbf{s}) = -\frac{1}{2}\mathbf{s}^\top \mathbf{W} \mathbf{s} - \mathbf{b}^\top \mathbf{s}$$

- $\mathbf{W}$：重み行列（対称、対角成分は0）
- $\mathbf{b}$：バイアスベクトル

### 3.3 エネルギーの直感的理解

**相互作用項** $-w_{ij} s_i s_j$：

| $w_{ij}$ | $s_i, s_j$ の関係 | エネルギーへの寄与 | 解釈 |
|----------|------------------|-------------------|------|
| 正 (+) | 同じ値（両方1） | 負（減少） | 協調すると安定 |
| 正 (+) | 異なる値 | 0 | - |
| 負 (-) | 同じ値（両方1） | 正（増加） | 協調すると不安定 |

**バイアス項** $-b_i s_i$：
- $b_i > 0$：ユニット $i$ が活性化しやすい
- $b_i < 0$：ユニット $i$ が非活性になりやすい

### 3.4 可視・隠れユニットを分離した表現

可視ユニット $\mathbf{v}$ と隠れユニット $\mathbf{h}$ を明示すると：

$$E(\mathbf{v}, \mathbf{h}) = -\mathbf{v}^\top \mathbf{W} \mathbf{h} - \mathbf{b}^\top \mathbf{v} - \mathbf{c}^\top \mathbf{h} - \mathbf{v}^\top \mathbf{U} \mathbf{v} - \mathbf{h}^\top \mathbf{V} \mathbf{h}$$

- $\mathbf{W}$：可視-隠れ間の重み
- $\mathbf{U}$：可視-可視間の重み
- $\mathbf{V}$：隠れ-隠れ間の重み
- $\mathbf{b}, \mathbf{c}$：それぞれのバイアス

### 3.5 自由エネルギー

隠れユニットを周辺化した**自由エネルギー**：

$$F(\mathbf{v}) = -\log \sum_{\mathbf{h}} \exp(-E(\mathbf{v}, \mathbf{h}))$$

これを使うと、可視ユニットの確率は：

$$P(\mathbf{v}) = \frac{\exp(-F(\mathbf{v}))}{Z}$$

**自由エネルギーの物理的解釈**：

$$F = \langle E \rangle - T \cdot S$$

- $\langle E \rangle$：平均エネルギー
- $S$：エントロピー（状態の多様性）

低い自由エネルギー = 低エネルギー、または高エントロピー（多くの隠れ状態が可能）

### 3.6 エネルギー地形

エネルギー関数は「地形」として視覚化できる：

```
エネルギー
    ^
    |     /\        /\
    |    /  \  /\  /  \
    |   /    \/  \/    \
    |  /                \
    | /      ★          \
    |/_______↓___________\___ 状態空間
           低エネルギー
           （安定状態＝アトラクタ）
```

- **局所最小値**：周辺より低いが、最低ではない（訓練データの一部に対応）
- **大域最小値**：全体で最もエネルギーが低い

確率的な更新により、局所最小値から抜け出せる可能性がある（決定論的なホップフィールドネットワークとの違い）。

### 3.7 エネルギーと対数尤度の関係

訓練データ $\mathbf{v}$ の対数尤度：

$$\log P(\mathbf{v}) = -F(\mathbf{v}) - \log Z$$

学習の目標は $\log P(\mathbf{v})$ を最大化すること。これは：
1. 訓練データの自由エネルギー $F(\mathbf{v})$ を**下げる**
2. 分配関数 $\log Z$ を**下げる**（≒ 他の状態のエネルギーを上げる）

ことに相当する。

---

## まとめ：基礎編のポイント

1. **ボルツマンマシンは確率的生成モデル**：データの分布 $P(\mathbf{v})$ を学習する
2. **エネルギー関数で確率分布を定義**：$P(\mathbf{s}) \propto \exp(-E(\mathbf{s}))$
3. **低エネルギー = 高確率**：学習は「良いパターン」のエネルギーを下げる過程
4. **隠れユニットの役割**：データの潜在的構造を捉え、表現力を高める
5. **確率的更新**：局所最小値から脱出可能、ギブスサンプリングで平衡分布に収束

---

[次へ: 学習とRBM →](./02-learning-and-rbm.md)
